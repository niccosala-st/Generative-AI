{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JJ8P1zX5R2vo",
        "G0hSPRzniLJ7",
        "sdahNB7wgNSP",
        "slkOXTHUgPZK",
        "GlcjLQt4hEPr",
        "OFa5Aww3gyRu",
        "8SUd5hPOTkn1",
        "1tSOfwDeOpQ-",
        "sWN3MhKkIiGP",
        "Yfv6Hh8JIk7L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain"
      ],
      "metadata": {
        "id": "8AJ_XHJG5JpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain Ã¨ un framework open source per la creazione di applicazioni basate su modelli linguistici di grandi dimensioni (LLM).\n",
        "LangChain fornisce strumenti e astrazioni per migliorare la personalizzazione, l'accuratezza e la pertinenza delle informazioni generate dai modelli. Ad esempio, gli sviluppatori possono utilizzare i componenti LangChain per creare nuove catene di prompt o personalizzare i modelli esistenti. LangChain include anche componenti che consentono agli LLM di accedere a nuovi set di dati senza riqualificazione."
      ],
      "metadata": {
        "id": "_McKUrKF5MNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "j_aYJN-gfVrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import logging"
      ],
      "metadata": {
        "id": "HKu8wdFzkCDD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "metadata": {
        "id": "RBcbEsz2pfUg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test LLM Google (Free - HugginFace)"
      ],
      "metadata": {
        "id": "JJ8P1zX5R2vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proviamo ad utilizzare un LLM free sviluppato da Google (***google/flan-t5-large***) scaricabile da HugginFace per fare qualche test preliminare."
      ],
      "metadata": {
        "id": "1x8ufyxb4V8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "pDJ2Ulq7xRBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "AnE90G81xO8N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'google/flan-t5-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100\n",
        ")\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "6uCnlkiKlnbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ST-bot\\n[Digit 'x' and confirm to quit the conversation]\\n\\n- - -\")\n",
        "question = \"\"\n",
        "\n",
        "while True:\n",
        "    question = input(\"\\nAsk me something:\\n> \")\n",
        "    if question == 'x':\n",
        "        break\n",
        "    answer = local_llm(question)\n",
        "\n",
        "    print(f\"\\nAssistant: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKd67lE8qSRU",
        "outputId": "1c223a57-a041-4a57-bc9a-88e3e5f95a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ST-bot\n",
            "[Digit 'x' and confirm to quit the conversation]\n",
            "\n",
            "- - -\n",
            "\n",
            "Ask me something:\n",
            "> hello\n",
            "\n",
            "Assistant: i'm a sailor\n",
            "\n",
            "Ask me something:\n",
            "> how you doin sailor?\n",
            "\n",
            "Assistant: good\n",
            "\n",
            "Ask me something:\n",
            "> x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain con memoria (Q&A)"
      ],
      "metadata": {
        "id": "1iscowFGdyPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questa sezione andiamo a creare delle chain dotate di memoria per sostenere una semplice conversazione di domande e risposte."
      ],
      "metadata": {
        "id": "vnkDNu5yiKEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurazione"
      ],
      "metadata": {
        "id": "G0hSPRzniLJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic\n",
        "!pip install langchain-google-vertexai"
      ],
      "metadata": {
        "id": "9x9gcuvuedZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from google.auth import credentials\n",
        "from google.oauth2 import service_account\n",
        "import google.cloud.aiplatform as aiplatform\n",
        "\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory, ConversationSummaryBufferMemory, ConversationBufferWindowMemory\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "import vertexai\n",
        "from anthropic import AnthropicVertex"
      ],
      "metadata": {
        "id": "7ZDQJan5nToa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lettura JSON e aggiornamento parametri\n",
        "with open(\n",
        "    \"service_account.json\"\n",
        ") as f:\n",
        "    credentials = json.load(f)\n",
        "\n",
        "my_credentials = service_account.Credentials.from_service_account_info(\n",
        "    credentials\n",
        ")\n",
        "\n",
        "# Inizializzazione AI Platform\n",
        "aiplatform.init(\n",
        "    credentials=my_credentials,\n",
        ")\n",
        "\n",
        "with open(\"service_account.json\", encoding=\"utf-8\") as f:\n",
        "    project_json = json.load(f)\n",
        "    project_id = project_json[\"project_id\"]\n",
        "\n",
        "# Inizializzazione Vertex AI\n",
        "vertexai.init(project=project_id, location=\"europe-west1\")"
      ],
      "metadata": {
        "id": "d-oU78blnR1n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI(model_name=\"text-bison@002\", max_output_tokens=50)"
      ],
      "metadata": {
        "id": "B6liBQ9-sWgE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facciamo una prova per vedere se siamo connessi."
      ],
      "metadata": {
        "id": "5WNvNzrewGSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = input(\"Ask me something\\n> \")\n",
        "answer = llm.invoke(question)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "sN1GPvoVvUQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memoria"
      ],
      "metadata": {
        "id": "Kh9AAXx2iOze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sperimentiamo secondo tre diversi metodi presentati nelle prossime sezioni come aggiungere il componente di memoria alle nostre conversazioni."
      ],
      "metadata": {
        "id": "JZWvbBM5jj6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Buffer memory"
      ],
      "metadata": {
        "id": "sdahNB7wgNSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiene in memoria la cronologia della conversazione."
      ],
      "metadata": {
        "id": "Zw2cgPJN3jaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory_buffer = ConversationBufferMemory()\n",
        "\n",
        "conversation_buffer = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=memory_buffer\n",
        ")"
      ],
      "metadata": {
        "id": "d5S0B_eb5DnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I have a black cat called Meowton\"\n",
        "print(conversation_buffer.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK4LgZSOkFfE",
        "outputId": "6db69db8-e552-4204-b82b-bdea0e0bb746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello! That's a great name for a cat. Black cats are often seen as symbols of mystery and magic. Did you know that in ancient Egypt, cats were revered as sacred animals and were often mummified after they died?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Can you tell me what is the name of my cat?\"\n",
        "print(conversation_buffer.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhMWgSn4kZke",
        "outputId": "81d051a9-9926-4dfa-89d0-bc69216827b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You mentioned that your cat's name is Meowton. Is there anything else you'd like to know about your cat?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_buffer.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6wcPG6ElqkH",
        "outputId": "8f430f8e-70a9-488b-febc-cccb67534d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: I have a black cat called Meowton\n",
            "AI:  Hello! That's a great name for a cat. Black cats are often seen as symbols of mystery and magic. Did you know that in ancient Egypt, cats were revered as sacred animals and were often mummified after they died?\n",
            "Human: Can you tell me what is the name of my cat?\n",
            "AI:  You mentioned that your cat's name is Meowton. Is there anything else you'd like to know about your cat?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Buffer Window memory"
      ],
      "metadata": {
        "id": "slkOXTHUgPZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiene in memoria la cronologia della conversazione fino a k messaggi precedenti all'utimo."
      ],
      "metadata": {
        "id": "byaa4UZc3oqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory_window = ConversationBufferWindowMemory(k=2)\n",
        "\n",
        "conversation_window = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=memory_window\n",
        ")"
      ],
      "metadata": {
        "id": "lox1x-b7g0c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I have a black cat called Meowton\"\n",
        "print(conversation_window.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz-75JLGmA--",
        "outputId": "24accf8d-46e9-4c98-8f9b-22a35523286d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello! That's a great name for a cat. Black cats are often seen as symbols of mystery and magic. Did you know that in ancient Egypt, cats were revered as sacred animals and were often mummified after they died?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I have a white dog called Barkton\"\n",
        "print(conversation_window.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOt-C6jlmDjx",
        "outputId": "34b5d6e6-5bd1-460d-efd4-bcc072d7b237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Oh, how lovely! White dogs are often seen as symbols of purity and innocence. Did you know that the ancient Romans believed that white dogs had the power to ward off evil spirits?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I have a red fish called Nemo\"\n",
        "print(conversation_window.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pJ9tipnmMeE",
        "outputId": "4e5dabb1-40f7-48ac-a3dd-2ce9c1bb5251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " That's a great name for a fish! Red fish are often seen as symbols of good luck and prosperity. Did you know that in ancient China, red fish were often kept in ponds and aquariums as a way to attract wealth and good fortune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Do you remember the name of my cat, my dog and my fish?\"\n",
        "print(conversation_window.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFzQCpCEm0QE",
        "outputId": "b4aae1f5-92df-40a0-f5dd-a0cc37a2c718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Yes, you mentioned that your dog's name is Barkton, your fish's name is Nemo, and you did not mention the name of your cat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non si ricorda il nome del gatto perchÃ¨ abbiamo impostato come finestra di memoria k=2, quindi ricorderÃ  le informazioni fino a due messaggi precedenti a quello appena inoltrato."
      ],
      "metadata": {
        "id": "8Sze7brnnv0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_window.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRggs02noLrm",
        "outputId": "1ddb1e9c-7157-4793-97c1-f085664c65d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: I have a red fish called Nemo\n",
            "AI:  That's a great name for a fish! Red fish are often seen as symbols of good luck and prosperity. Did you know that in ancient China, red fish were often kept in ponds and aquariums as a way to attract wealth and good fortune\n",
            "Human: Do you remember the name of my cat, my dog and my fish?\n",
            "AI:  Yes, you mentioned that your dog's name is Barkton, your fish's name is Nemo, and you did not mention the name of your cat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Buffer Summary memory"
      ],
      "metadata": {
        "id": "GlcjLQt4hEPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiene in memoria la cronologia della conversazione ed Ã¨ in grado di farne un riassunto."
      ],
      "metadata": {
        "id": "cNFwcqDr3uYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory_summary = ConversationSummaryBufferMemory(llm=llm)\n",
        "\n",
        "conversation_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory_summary,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "ai6MnSg3htMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I have a black cat called Meowton\"\n",
        "print(conversation_summary.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APv3DZ0bocd4",
        "outputId": "16828b02-9b08-490b-cee0-48367f7fa77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello! That's a great name for a cat. Black cats are often seen as symbols of mystery and magic. Did you know that in ancient Egypt, cats were revered as sacred animals and were often mummified after they died?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"I have a white dog called Barkton\"\n",
        "print(conversation_summary.predict(input=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYyCS_B-oc9a",
        "outputId": "93115821-3ecf-478d-fa1c-8d807b7cf2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Oh, how lovely! White dogs are often seen as symbols of purity and innocence. Did you know that the breed of dog most commonly associated with the color white is the Samoyed, which originated in Siberia and was bred to withstand harsh Arctic conditions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_summary.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyO5YI_Roo-h",
        "outputId": "285765f1-cb46-4516-fb71-ac1130d32f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='I have a black cat called Meowton'), AIMessage(content=\" Hello! That's a great name for a cat. Black cats are often seen as symbols of mystery and magic. Did you know that in ancient Egypt, cats were revered as sacred animals and were often mummified after they died?\"), HumanMessage(content='I have a white dog called Barkton'), AIMessage(content=' Oh, how lovely! White dogs are often seen as symbols of purity and innocence. Did you know that the breed of dog most commonly associated with the color white is the Samoyed, which originated in Siberia and was bred to withstand harsh Arctic conditions')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otteniamo ora un riassunto della conversazione"
      ],
      "metadata": {
        "id": "_QCVzKC5qs44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = memory_summary.chat_memory.messages\n",
        "previous_summary = \"\"\n",
        "\n",
        "# Riassume la conversazione\n",
        "memory_summary.predict_new_summary(messages, previous_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "IP4cHRsMqaJN",
        "outputId": "1220974a-1ce9-426d-8eee-fa061a583e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The human introduces their pets, a black cat named Meowton and a white dog named Barkton. The AI comments on the symbolism and historical significance associated with black cats and white dogs, respectively.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "OFa5Aww3gyRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationSummaryBufferMemory(llm=llm)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "QYHso62qi_c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ST-bot\\n[Say 'bye' and confirm to quit the conversation]\\n\\n- - -\")\n",
        "question = \"\"\n",
        "\n",
        "while True:\n",
        "    question = input(\"\\nYou:\\n> \")\n",
        "    if question.lower() == \"bye\":\n",
        "        print(\"\\nChat terminated.\")\n",
        "        break\n",
        "\n",
        "    answer = conversation.predict(input=question)\n",
        "    print(f\"\\nAssistant:\\n>{answer}\")\n",
        "\n",
        "print(\"\\nRiassunto della conversazione:\")\n",
        "memory.predict_new_summary(memory.chat_memory.messages, \"\")\n",
        "\n",
        "# How many eggs do I need for a carbonara for 5 people?\n",
        "# With carbonara, what's better between red and white wine?\n",
        "# How long does it take to cook carbonara generally?\n",
        "# Bye"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "qAnn5sa4xmuD",
        "outputId": "ba7181f6-3ba4-45db-93c5-cd4300b4fcf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ST-bot\n",
            "[Say 'bye' and confirm to quit the conversation]\n",
            "\n",
            "- - -\n",
            "\n",
            "You:\n",
            "> How many eggs do I need for a carbonara for 5 people?\n",
            "\n",
            "Assistant:\n",
            "> A traditional carbonara recipe usually doesn't include eggs. However, there are variations of carbonara that do include eggs. One common variation is to add one egg yolk per person, so for 5 people, you would need 5 egg yolks\n",
            "\n",
            "You:\n",
            "> With carbonara, what's better between red and white wine?\n",
            "\n",
            "Assistant:\n",
            "> White wine is typically used in carbonara, as it adds a delicate flavor that complements the richness of the dish. Red wine can also be used, but it will give the carbonara a more robust flavor. Ultimately, the choice between red and white\n",
            "\n",
            "You:\n",
            "> How long does it take to cook carbonara generally?\n",
            "\n",
            "Assistant:\n",
            "> Cooking time for carbonara can vary depending on the recipe and personal preferences. Generally, it takes around 15-20 minutes to cook carbonara. This includes the time to boil the pasta, prepare the sauce, and combine everything together.\n",
            "\n",
            "You:\n",
            "> bye\n",
            "\n",
            "Chat terminated.\n",
            "\n",
            "Riassunto della conversazione:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The human asks how many eggs they need for a carbonara for 5 people. The AI says that a traditional carbonara recipe doesn't include eggs, but there are variations that do. One common variation is to add one egg yolk per person\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG"
      ],
      "metadata": {
        "id": "khm7jg_z5C1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurazione"
      ],
      "metadata": {
        "id": "8SUd5hPOTkn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain langsmith pypdf sentence-transformers"
      ],
      "metadata": {
        "id": "SmtY8IVgBKn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings"
      ],
      "metadata": {
        "id": "pshWYjTA8wBG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_API_KEY'] = 'ls__b3a86f568a6948868904c54eda03574a'"
      ],
      "metadata": {
        "id": "qo4IpZ3fTD5H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Breve test RAG"
      ],
      "metadata": {
        "id": "NzR9tR4rTqXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento e lettura di tutti i documenti .pdf\n",
        "loader = DirectoryLoader(f'', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "9Teslv6oSw5Q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creazione degli split all'interno del testo con dimensione del chunk e sovrapposizione fissati\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "YXpSNHlEBy3P"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizzo di un modello di embedding free esistente per la generazione di embedding\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "f-_SX5QfDqFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test per vedere se trova informazioni rilevanti rispetto alle risorse (.pdf)\n",
        "query = \"Why Community Involvement Matters?\"\n",
        "matching_docs = vectorstore.similarity_search(query)\n",
        "\n",
        "matching_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQdoz0iQD_U8",
        "outputId": "4384511b-cb8c-4c3f-ddad-34395c9460f1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='their friendship a shining beacon of warmth and joy for all who knew them.', metadata={'page': 1, 'source': 'billy.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modello di prompt predefinito\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "3s-QDkIOMRum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione di formattazione del testo\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "3kRs1pKLMdFH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testiamo una chain che recupera le informazioni richieste tra le risorse esistenti e le rielabora"
      ],
      "metadata": {
        "id": "Aap9C2NBTMD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain.invoke(\"Why Community Involvement Matters?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "huUfOOwWMgd7",
        "outputId": "91699dcc-7995-4e4a-c49d-833c3b92f6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Community involvement is crucial because it allows individuals to pool their resources, knowledge, and creativity to create a positive impact on the environment. By working together, communities can organize clean-up drives, tree planting activities, and educational programs that not only beautify'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain con memoria (Q&A + RAG)"
      ],
      "metadata": {
        "id": "ZsQ-AUcmRfeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test con risorse fissate"
      ],
      "metadata": {
        "id": "1tSOfwDeOpQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "X4GI5GKHW3hR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resources = \"my nose is red\""
      ],
      "metadata": {
        "id": "r46izxn6OKqP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know or retrieves from the external resources.\n",
        "\n",
        "Current conversation:\n",
        "{history}{resources}\n",
        "Human: {input}\n",
        "AI Assistant:\"\"\"\n",
        "PROMPT = PromptTemplate.from_template(template).partial(resources=resources)\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "TQy52KukWzdY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = conversation.predict(input=\"I have a blue dog\")\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aaje_banaAL4",
        "outputId": "19fc866a-604a-4640-e057-4a7d55a118da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assistant:\n",
            "> Okay, so your dog is blue. Can you tell me more about your dog? What's its name and breed?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = conversation.predict(input=\"What's the color of my dog and my nose?\")\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7y-leuaAdS",
        "outputId": "fadc91e6-e475-4779-b313-26d0e4ea9868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assistant:\n",
            "> Based on the information you've provided, your dog is blue and your nose is red. Is there anything else you'd like to know about your dog or your nose?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test con risorse esterne"
      ],
      "metadata": {
        "id": "bw-4eyjIKP_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento e lettura di tutti i documenti .pdf\n",
        "loader = DirectoryLoader(f'', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "# Creazione degli split all'interno del testo con dimensione del chunk e sovrapposizione fissati\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(documents)\n",
        "\n",
        "# Utilizzo di un modello di embedding free esistente per la generazione di embedding\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "j7ymXuWNO6kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creaimo una funzione che consenta la ricerca sia sui dati di addestramento che dalle risorse esterne."
      ],
      "metadata": {
        "id": "jGfqmbrSRstw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_with_resources(input, conversation, template, verbose):\n",
        "    # Recupera le risorse\n",
        "    resources = vectorstore.similarity_search(input)\n",
        "\n",
        "    # Crea il prompt personalizzato per le risorse recuperate e assegnalo alla conversazione\n",
        "    prompt = PromptTemplate.from_template(template).partial(resources=resources)\n",
        "    conversation.prompt = prompt\n",
        "\n",
        "    # Elabora la risposta\n",
        "    answer = conversation.predict(input=input)\n",
        "\n",
        "    # Stampa le risorse trovate se richiesto\n",
        "    if(verbose):\n",
        "        print(resources)\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "PGzaFO4DJEvN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo template, memoria e chain per il nostro test."
      ],
      "metadata": {
        "id": "ljzJfVc4R0gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know or retrieves from the external resources.\n",
        "\n",
        "Current conversation:\n",
        "{history}{resources}\n",
        "Human: {input}\n",
        "AI Assistant:\"\"\"\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "JbumcZLcI8gS"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facciamo una domanda generica per vedere se il modello Ã¨ in grado di rispondere con i suoi dati di addestramento:"
      ],
      "metadata": {
        "id": "Slq4u9KwSapd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_with_resources(\n",
        "    input=\"what can you tell me about dogs?\",\n",
        "    conversation=conversation,\n",
        "    template=template,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG-SUmQsJhlY",
        "outputId": "d1a30af8-bfb5-4f06-c4a5-a6d75cd6a3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assistant:\n",
            "> Dogs, scientifically known as Canis lupus familiaris, are domesticated mammals that have been a part of human society for thousands of years. They are believed to have descended from wolves and have evolved into various breeds with distinct physical and behavioral characteristics. Dogs are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora chiediamogli qualcosa di specifico sui dati esterni (.pdf):"
      ],
      "metadata": {
        "id": "k417n9gcSf1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_with_resources(\n",
        "    input=\"What are the names of the blue dog and the red cat?\",\n",
        "    conversation=conversation,\n",
        "    template=template,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2wwF1ifJxyf",
        "outputId": "40f21386-f251-4c54-c65f-264247cdf596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"Molly the blue dogOnce upon a time, in a quaint little village nestled between rolling hills and lush forests, there lived a peculiar dog named Molly. What made Molly so unique was her striking blue fur, a rare sight that never failed to captivate anyone who laid eyes on her.Molly was not just any ordinary dog; she possessed a keen intelligence and a gentle soul that endeared her to all who knew her. Despite her unusual appearance, she was beloved by the villagers, who often sought her company during their daily walks through the countryside.One sunny afternoon, as Molly roamed the village streets, she stumbled upon a group of children playing in the town square. Intrigued by her azure coat, the children ï¬ocked around her, their laughter ï¬lling the air as they showered her with affection.Among the children was a little girl named Emily, whose eyes sparkled with wonder at the sight of Molly's radiant blue fur. Instantly drawn to the enchanting dog, Emily approached Molly with\", metadata={'page': 0, 'source': 'molly.pdf'}), Document(page_content=\"Molly the blue dogOnce upon a time, in a quaint little village nestled between rolling hills and lush forests, there lived a peculiar dog named Molly. What made Molly so unique was her striking blue fur, a rare sight that never failed to captivate anyone who laid eyes on her.Molly was not just any ordinary dog; she possessed a keen intelligence and a gentle soul that endeared her to all who knew her. Despite her unusual appearance, she was beloved by the villagers, who often sought her company during their daily walks through the countryside.One sunny afternoon, as Molly roamed the village streets, she stumbled upon a group of children playing in the town square. Intrigued by her azure coat, the children ï¬ocked around her, their laughter ï¬lling the air as they showered her with affection.Among the children was a little girl named Emily, whose eyes sparkled with wonder at the sight of Molly's radiant blue fur. Instantly drawn to the enchanting dog, Emily approached Molly with\", metadata={'page': 0, 'source': 'molly.pdf'}), Document(page_content=\"Molly the blue dogOnce upon a time, in a quaint little village nestled between rolling hills and lush forests, there lived a peculiar dog named Molly. What made Molly so unique was her striking blue fur, a rare sight that never failed to captivate anyone who laid eyes on her.Molly was not just any ordinary dog; she possessed a keen intelligence and a gentle soul that endeared her to all who knew her. Despite her unusual appearance, she was beloved by the villagers, who often sought her company during their daily walks through the countryside.One sunny afternoon, as Molly roamed the village streets, she stumbled upon a group of children playing in the town square. Intrigued by her azure coat, the children ï¬ocked around her, their laughter ï¬lling the air as they showered her with affection.Among the children was a little girl named Emily, whose eyes sparkled with wonder at the sight of Molly's radiant blue fur. Instantly drawn to the enchanting dog, Emily approached Molly with\", metadata={'page': 0, 'source': 'molly.pdf'}), Document(page_content=\"In a cozy little neighborhood, where the houses clustered together like old friends, there lived a red cat named Billy. Billy wasn't your ordinary feline; his fur was a brilliant shade of crimson, a striking contrast against the backdrop of the quaint streets and ï¬ower-ï¬lled gardens.Despite his ï¬ery appearance, Billy had a heart as gentle as a summer breeze. He spent his days roaming the cobblestone alleys, his keen eyes taking in every sight and sound of the bustling neighborhood.Billy's favorite spot to lounge was beneath the grand oak tree in the town square. From his perch, he would watch as the world went by, greeting passersby with a friendly purr and a ï¬ick of his tail.One day, as Billy basked in the warm sunlight, he noticed a little girl named Lily sitting on a nearby bench, her eyes ï¬lled with sadness. Sensing her melancholy, Billy padded over to her side, his red fur glowing in the afternoon light.Lily looked up in surprise as Billy approached, but her surprise quickly\", metadata={'page': 0, 'source': 'billy.pdf'})]\n",
            "\n",
            "Assistant:\n",
            "> The blue dog's name is Molly, and the red cat's name is Billy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recupero risorse da internet"
      ],
      "metadata": {
        "id": "IzsjzMYhUpzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurazione"
      ],
      "metadata": {
        "id": "sWN3MhKkIiGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyduckduckgosearch\n",
        "!pip install -U duckduckgo-search"
      ],
      "metadata": {
        "id": "ZVMLPjmnc14A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from websearch import search\n",
        "from langchain.agents import AgentType,initialize_agent,load_tools"
      ],
      "metadata": {
        "id": "BF2xEQAzc8w2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cerca nei dati di addestramento, nelle risorse e suggerisci da internet"
      ],
      "metadata": {
        "id": "Yfv6Hh8JIk7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo una funzione che generi le risposte cercando tra i dati di addestramento + risorse esterne e fornisca suggerimenti utili rispetto alla richiesta dalle risorse online."
      ],
      "metadata": {
        "id": "4wuNIVy3VuW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_with_resourcers_and_suggest(input, conversation, template, verbose):\n",
        "    partial_answer = answer_with_resources(input, conversation, template, verbose)\n",
        "\n",
        "    tools = load_tools([\"ddg-search\"], llm=conversation.llm)\n",
        "    agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
        "    search_result = agent.run(input)\n",
        "\n",
        "    return partial_answer + \"\\n\\nPotrebbe interessarti (da DuckDuckGo):\\n\" + search_result"
      ],
      "metadata": {
        "id": "QgAz3-_mVna0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_with_resourcers_and_suggest(\n",
        "    input=\"What are the names of the blue dog and the red cat?\",\n",
        "    conversation=conversation,\n",
        "    template=template,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_cWCziPfKJz",
        "outputId": "b0702fa3-4a09-454e-a3ae-1c9a5038cd34"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assistant:\n",
            "> The blue dog's name is Molly, and the red cat's name is Billy.\n",
            "\n",
            "Potrebbe interessarti (da DuckDuckGo):\n",
            "The blue dog can be an Australian Shepherd or a Blue Heeler or Kerry Blue Terrier. The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cerca nei dati di addestramento e nelle risorse. Se nelle risorse non c'Ã¨ corrispondenza con la domanda dell'utente, cerca su internet"
      ],
      "metadata": {
        "id": "QwMr6XGJIreN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "BmH2SNzVK0F5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creaimo una funzione che verifichi la corripondenza tra la domanda dell'utente e i documenti. Il grado di similaritÃ  Ã¨ regolato tramite il parametro ***relevance_treshold***."
      ],
      "metadata": {
        "id": "VS1asb5ETh0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_similarity_with_treshold(input, relevance_treshold, verbose):\n",
        "\n",
        "    texts = []\n",
        "    max_score = 0\n",
        "\n",
        "    # Misurazione della similaritÃ  tra richiesta e risorse\n",
        "    for doc in documents:\n",
        "        relevance = vectorstore.similarity_search_with_relevance_scores(input)[0]\n",
        "        text = relevance[0].page_content\n",
        "        score = relevance[1]\n",
        "\n",
        "        # Salva se rilevante\n",
        "        if score > relevance_treshold:\n",
        "            texts.append(text)\n",
        "            max_score = score\n",
        "\n",
        "    if verbose:\n",
        "        if max_score == 0:\n",
        "            print(\"Couldn't retrieve relevant documents\")\n",
        "        else:\n",
        "            print(f\"Document retrieved with max relevance: {round(max_score, 3)}\")\n",
        "\n",
        "    return texts, max_score"
      ],
      "metadata": {
        "id": "hTmITtjnTH-5"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo la funzione che consenta di rispondere con i dati di addestramento + le risorse esterne, se queste ultime sono disponibili, altrimenti con i dati di addestramento + le risorse online."
      ],
      "metadata": {
        "id": "3i_7n7-JT4iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_with_resourcers_or_online(input, conversation, template, relevance_treshold, verbose):\n",
        "    # Recupera le risorse se rilevanti\n",
        "    texts, score = check_similarity_with_treshold(input, relevance_treshold, verbose)\n",
        "\n",
        "    # Se non sono state recuperate informazioni rilevanti dalle risorse esterne, recuperale da internet\n",
        "    if score == 0:\n",
        "        tools = load_tools([\"ddg-search\"], llm=conversation.llm)\n",
        "        agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
        "        search_result = agent.run(input)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"From internet: {search_result}\")\n",
        "\n",
        "        prompt = PromptTemplate.from_template(template).partial(resources=search_result)\n",
        "        conversation.prompt = prompt\n",
        "        answer = conversation.predict(input=input)\n",
        "\n",
        "    # Modella il prompt con le risorse recuperate online\n",
        "    else:\n",
        "        prompt = PromptTemplate.from_template(template).partial(resources=texts)\n",
        "        conversation.prompt = prompt\n",
        "        answer = answer_with_resources(input, conversation, template, False)\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "GPm5DsdqLjH-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proviamo a chiedere al modello se conosce LangChain. Questo, non essendo aggiornato quotidianamente, dai soli dati di addestramento non sarÃ  in grado di generare una risposta utile. AndrÃ  a cercare tra le risorse esterne, ma anche qua non troverÃ  nulla. Quindi, cercando tra le risorse online, sarÃ  in grado di trovare qualcosa di pertinente con la richiesta e creare un output adeguato."
      ],
      "metadata": {
        "id": "27K4Z8gMUHrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_with_resourcers_or_online(\n",
        "    input=\"Do you know Langchain?\",\n",
        "    conversation=conversation,\n",
        "    template=template,\n",
        "    relevance_treshold=0.2,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyAvks1zEbNn",
        "outputId": "775e2775-4c89-41d6-ea08-15f436f2e319"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't retrieve relevant documents\n",
            "From internet: LangChain is an open-source Python library for building LLM-powered applications.\n",
            "\n",
            "Assistant:\n",
            "> Yes, I know about LangChain. LangChain is an open-source Python library that enables developers to build language model-powered applications. It provides a comprehensive set of tools and functionalities for training, fine-tuning, and deploying language models. Lang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora proviamo a chiedergli qualcosa che sappiamo trovarsi tra le risorse esterne. Per questo il modello, trovando ciÃ² che cerca tra i pdf, potrÃ  rispondere senza andare a interrogare le risorse online."
      ],
      "metadata": {
        "id": "GhmcdD8AUjP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_with_resourcers_or_online(\n",
        "    input=\"Do you know the story of the red cat?\",\n",
        "    conversation=conversation,\n",
        "    template=template,\n",
        "    relevance_treshold=0.2,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"\\nAssistant:\\n>{answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm5jRVdBMCoo",
        "outputId": "24bcbcc2-b8ae-45e4-b21b-099f8ebe7ddc"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document retrieved with max relevance: 0.319\n",
            "\n",
            "Assistant:\n",
            "> Yes, I know the story of the red cat named Billy. Billy lived in a cozy neighborhood filled with quaint streets and flower-filled gardens. Despite his fiery red fur, Billy had a gentle heart and spent his days roaming the cobblestone alleys,\n"
          ]
        }
      ]
    }
  ]
}